% !TeX root = ../Main.tex
\section{The approach}
\label{sec:framework}

\def\safeconset {\ensuremath{\declamodel^{\mathrm{S}}}}
\def\safeconlist {\ensuremath{\safeconset_{\mathrm{list}}}}
\def\safecon {\ensuremath{\constraint^{\mathrm{\safeconset}}_i}}
\def\unsafeconset {\ensuremath{\declamodel^{\mathrm{U}}}}
\def\unsafeconlist {\ensuremath{\unsafeconset_{\mathrm{list}}}}
\def\unsafecon {\ensuremath{\constraint^{\mathrm{\unsafeconset}}_i}}
\def\goodconset {\ensuremath{\declamodel^{\mathrm{R}}}}
\def\blackboard {\ensuremath{\declamodel^{\mathrm{V}}}}
\def\languageFunctor {\ensuremath{\mathscr{L}}}
\def\automFunctor {\ensuremath{\mathscr{A}}}
\def\regexpFunctor {\ensuremath{\mathscr{E}_\mathrm{Reg}}}
\newcommand{\languageFunc}[1] {\ensuremath{\languageFunctor\left(#1\right)}}
\newcommand{\automFunc}[1] {\ensuremath{\automFunctor\left(#1\right)}}
\newcommand{\regexpFunc}[1] {\ensuremath{\regexpFunctor\left(#1\right)}}

This section describes how we tackle the problem of finding a non-redundant consistent \gls{declare} model in a way that reduces the intractable theoretical complexity. % yet allowing for a non-trivial suboptimal solution.
First, we present the algebraic structure on top of which the check of redundancies and conflicts is performed: It bases upon the mapping of the conjunction of \gls{declare} constraints to the product of \glspl{fsa}.
Thereafter, we define and discuss the algorithm that allows us to pursue our objective.
In particular, we rely on the associativity of the product of \glspl{fsa}. This property allows us to check every \gls{con} one at a time and include it in a temporary solution. This is done by saving the product of the \gls{con}s checked so far with the current one. For the selection of the next candidate constraint to check, we make use of a greedy heuristic, that explores the search space by gathering at every step the \gls{con} that has the highest \gls{support}, or is most likely to imply the highest number of other \glspl{con}. The algorithm proceeds without visiting the same node in the search space twice.

\subsection{Declare models as automata}
As already shown in \cite{DiCiccio.Mecella/CIDM2013:TwoStepFast}, \gls{declare} \glspl{con} can be formulated as regular expressions (REs) over the \gls{logalph}. The assumption is that every \gls{task} in the \gls{logalph} is bi-univocally identified by a character. Thus, \glspl{evttrace} can be assimilated to finite sequences of characters (i.e., strings) and regular languages represent the \glspl{evttrace} allowed by a \gls{declare} model.

Using the \texttt{POSIX} wildcards, we can express, e.g.,
$\Init{\taska}$
as
\texttt{a.*},
and
$\Resp{\taska}{\taskb}$
as
\texttt{[{\nore}a]*(a.*b)*[{\nore}a]*}.
The comprehensive list of transpositions for \gls{declare} \glspl{temp} is listed in \Cref{tab:model:declareconstraintsandregexps} and explained in \cite{Prescher.etal/SIMPDA2014:FromDeclarativeProcesses}.
Henceforth, we will refer to such mapping as
$\regexpFunc{\constraint}$,
which takes as input a \gls{con} {\constraint} and returns the corresponding RE:
E.g., {\regexpFunc{\Resp{\taska}{\taskb}}$ = $\texttt{[{\nore}a]*(a.*b)*[{\nore}a]*}}.
Defining the operations of conjunction between \gls{declare} \glspl{con} ($\wedge$) and intersection between REs ($\mathtt{\&\&}$),
{\regexpFunctor} is a monoid homomorphism w.r.t.\ $\wedge$ and $\mathtt{\&\&}$.
In other words, given two \glspl{con}
{\constraint} and {\constraintPrime},
${\regexpFunc{\constraint \wedge \constraintPrime} = \regexpFunc{\constraint} \; \mathtt{\&\&} \; \regexpFunc{\constraintPrime}}$,
preserving closure, associativity and the identity element (resp., $\top$ and \texttt{.*}).

Since regular grammars are recognisable through REs \cite{ChomskyM58:finiteStateLanguages}, an RE can always be associated to a deterministic labelled \gls{fsa}, %(or \gls{fsa} for short)
which accepts all and only those finite strings that match the RE.
Formally, an \gls{fsa} is a tuple
$ \mathcal{S} = \langle \Sigma, S, \autominitstate , \mathcal{\delta}, S^\mathit{f} \rangle $, where:
$\Sigma$ is the alphabet;
$S$ is the finite non-empty set of states;
$\autominitstate \in S$ is the initial state;
$\mathcal{\delta} : S \times \Sigma \rightarrow S$ is the transition function;
$S^\mathit{f} \subseteq S$ is the set of final states.
%
Naming as $\automFunctor$ the operation leading from an RE to an \gls{fsa}, we thus have that a \gls{declare} \gls{con} can be associated with its corresponding \gls{fsa},
${\autom^\constraint = \automFunc{\regexpFunc{\constraint}}}$.
Henceforth, we also call $\autom^\constraint$ the {\constraint}-automaton.
We remark that, by applying $\automFunctor$ to the RE of a conjunction of constraints, we obtain an \gls{fsa} that exactly corresponds to the product $\times$ of the \glspl{fsa} for the individual constraints \cite{Gisburg66:languagesPreservation}:
${\automFunc{\regexpFunc{\constraint \wedge \constraintPrime}} = \automFunc{\regexpFunc{\constraint}} \times \automFunc{\regexpFunc{\constraintPrime}}}$. Also, we recall that the identity element for \glspl{fsa} is a single-state automaton whose unique state is both initial and accepting, and has a self-loop for each character in the considered alphabet.


%preserves as a monoid homomorphism the conjunction $\mathtt{\&\&}$ (a fortiori, $\wedge$) by the product $\times$ %between automata
% The identity element is for \glspl{fsa} a single-state automaton, both initial and accepting, with an looping upon it for each character.
% Therefore,
% ${\automFunc{\regexpFunc{\constraint \wedge \constraintPrime}} = \automFunc{\regexpFunc{\constraint}} \times \automFunc{\regexpFunc{\constraintPrime}}}$.
Given a model ${\declamodel = \left\lbrace \constraint_1, \ldots, \constraint_{|\declamodel|} \right\rbrace}$,
we can therefore implicitly describe the set of \glspl{evttrace} that comply with $\declamodel$ as the language accepted by the product of all $\constraint_i$-automata (for $i \in [1, |\declamodel|]$).
The language accepted by an \gls{fsa} $\autom$ will be denoted as $\languageFunc{\autom}$.
In the light of this discussion, our approach searches a solution to the problem of finding a non-redundant consistent \gls{declare} model within the \textbf{\gls{autopromo}}, i.e., the associative algebraic structure with identity element (the universe-set of \glspl{fsa}) and product operation $\times$. For the \gls{autopromo}, the property of commutativity also holds.

\subsection{The algorithm}

\input{algorithms/mainalgorithm.tex}
\input{algorithms/resolveconflicts.tex}

\Cref{alg:main} outlines the pseudocode of our technique.
Its input is a \gls{declare} model, \glssymbol{declamodel}, intended as a set of \glspl{con} $\constraint_1, \ldots, \constraint_{|\declamodel|}$.
For every $\constraint \in \declamodel$, we assume that its \gls{support}, \gls{conf} and \gls{intf} are given too, which is the usual condition when \glssymbol{declamodel} is the output of mining algorithms such as \gls{decmapmin} or \gls{minerful}.
\Cref{tab:runningexample:input} shows an example of {\declamodel}, defined on the \gls{logalph} $\left\lbrace \taska, \taskb, \taskc, \taskd \right\rbrace$.
We also assume that the same metrics are defined for those constraints that are not in \glssymbol{declamodel}, yet are either their subsuming, negated, \gls{fw} or \gls{bw} version. %(see \Cref{fig:subsum:map:rela}). %\todo{Marco: these must be defined in Section 2!}.
Again, this is common in the output of the aforementioned algorithms. For the sake of readability, these additional \glspl{con} are not reported in \Cref{tab:runningexample:input}.
\Cref{tab:runningexample:output} shows the output that corresponds to the post-processing of \Cref{tab:runningexample:input}.
\Glspl{con} that are considered as redundant are coloured in grey. Struck-out \glspl{con} are those that are in conflict with the others and thus dropped from the returned set.

Given \glssymbol{declamodel}, the first operation ``$\mathrm{removeSubsumptionHierarchyRedundancies}$'' prunes out redundant \glspl{con} based on the subsumption hierarchy. The procedure considers a removal of the subsuming \glspl{con} such that their \gls{support} is less than or equal to the subsumed one, and the elimination of \gls{fw} and \gls{bw} \glspl{con} if the related \gls{corelacon} has an equivalent support. Detail of this operations have already been described in \cite{DiCiccio.Mecella/ACMTMIS2015:DiscoveryDeclarativeControl}. The usefulness of this procedure resides in the fact that it reduces the number of candidate constraints to be considered, thus reducing the number of iterations performed by the algorithm.
In \Cref{tab:runningexample:output}, this operation is responsible for the dropping of {\Part{\taska}}, due to the fact that {\Init{\taska}} is known to hold true.

Thereafter, we partition \glssymbol{declamodel} into two subsets, i.e.:
\begin{inparaenum}[\itshape(i)\upshape]
\item {\safeconset}, consisting of those \glspl{con} that are verified over the entire \gls{evtlog} (i.e., having a \gls{support} of $1.0$), and
\item {\unsafeconset}, containing the remaining \glspl{con}.
\end{inparaenum}
The reason for doing this is that the former is guaranteed to have no conflict: Given the fact that constraints are mined using the alphabet of the \gls{evtlog}, those that have a support of $1.0$ can be conjoined, giving raise to a \emph{consistent} constraint model.
%that continue to have an overall support of $1.0$.

Even though constraints in {\safeconset} are guaranteed to be conflict-free, they could still contain redundancies. Therefore, the following part of the algorithm is dedicated to the elimination of redundant constraints from this set. To check redundancies, we employ the characterisation of constraints in terms of \glspl{fsa}. Instead, constraints in {\unsafeconset} may contain both redundancies and inconsistencies.
\Cref{tab:runningexample:output} presents the partition of \glssymbol{declamodel} into {\safeconset} and {\unsafeconset}.

\input{tables/ExampleInput.tex}


First, we initialise an \gls{fsa} {\autom} to be the identity element w.r.t.~automata product. In other words, {\autom} is initialised to accept any sequence of \glspl{evt} that map to a \gls{task} in the \gls{logalph}. This automata incrementally incorporates those constraints that are maintained in the filtered model. To set up the redundancy elimination in {\safeconset} as well as the redundancy and inconsistency elimination in {\unsafeconset}, we then order their constitutive constraints according the the following criteria (in descending order of priority):
%
%\Glspl{con} in {\safeconset} and {\unsafeconset} are thus ordered according to the following criteria:
\begin{inparaenum}[\itshape(i)\upshape]
\item descending \gls{support} (this is trivial for {\safeconset}, since all constraints have a support of $1.0$);%, only for {\unsafeconset} as all \glspl{con} in {\safeconset} have a \gls{support} of $1.0$;
\item category -- consider first \glspl{exicon}, then positive \glspl{relacon}, and finally \glspl{negacon};
\item descending \gls{conf};
\item descending \gls{intf}.
\end{inparaenum}
This ranking is of utmost importance, as it determines the priority with which \glspl{con} are analysed. The priority, in turn, implicitly defines the ``survival expectation'' of a constraint, as constraints that come later in the list are more likely to be pruned if they are either redundant or conflicting.


We briefly explain the reason for this multi-dimensional ranking.
\Gls{support} is the first criterion adopted, because we prefer to preserve those \glspl{con} that are satisfied in the most part of the log.
%
The category criterion is instead driven by the expertise acquired in the last years in the context of \gls{declare} mining \cite{Schunselaar.etal/IFM2012:PatternsLogBased,Maggi.etal/CAiSE2012:EfficientDiscoveryUnderstandable}. In particular, we tend to preserve those constraints that have the potential of inducing the removal of a massive amount of other constraints, due to redundancy.
As an example, consider the case of the $\mathit{Init}$ template: Given $\rho \in \logalph$, if $\Init{\rho}$ holds true, then also the \gls{relacon} $\Prec{\rho}{\sigma}$ is guaranteed to hold true, for every $\sigma \in \logalph \setminus \left\lbrace \rho \right\rbrace$. This means that, in the best case, $|\logalph| -1$ \glspl{con} will be removed because they are all redundant with $\Init{\rho}$. Similarly, consider the positive \gls{relacon} $\ChaResp{\rho}{\sigma}$: It implies $\NotChaSucc{\rho}{\sigma'}$ for every $\sigma' \in \logalph \setminus \{ \rho, \sigma \}$. Thus,  $\ChaResp{\rho}{\sigma}$ has the potential of triggering the removal of $|\logalph| -2$ negative \glspl{con} due to redundancy.
%
The last criteria adopted pertain \gls{conf} and \gls{intf}, in order to prefer those \glspl{con} whose parameters occur in most \glspl{evttrace}.
In \Cref{alg:main}, the computation of this ranking is encapsulated inside function ``$\textrm{sortBySupportCategoryConfidenceIF}$'', which returns a list of \glspl{con} ordered according to the aforementioned criteria.
In \Cref{tab:runningexample:output}, the result of the sorting is reported.

After the sorting, \glspl{con} are iteratively considered for inclusion in the refined model, by iterating through the corresponding ranked lists. % and considering the associativity of automata products.
\Glspl{con} in the list of {\safeconset}, i.e., $\safecon \in \safeconlist$, are only checked for redundancy, whereas \glspl{con} in {\unsafeconset}, $\unsafecon \in \unsafeconlist$, are checked for both redundancy and consistency.
For every constraint $\safecon \in \safeconlist$, redundancy is checked by leveraging language-inclusion. In particular, this is done by computing the \gls{fsa} $A^{\safecon}$ for $\safecon$, and then checking whether its generated language $\languageFunc{A^{\safecon}}$ is included inside $\languageFunc{A}$, which considers the contribution of all constraints maintained so far. If this is the case, then the constraint is dropped. Otherwise, $A$ is extended with the contribution of this new constraint (by computing the product $A \times A^{\safecon}$), and $\safecon$ is added to the set $\goodconset$ of constraints to be returned.
In the example of \Cref{tab:runningexample:output}, {\CoExi{\taska}{\taskd}} is analysed after the \glspl{exicon} {\Init{\taska}} and {\End{\taskd}}, based on the preliminary sorting operation.
It thus turns out to be redundant, because {\Init{\taska}} and {\End{\taskd}} already specify that both {\taska} and {\taskd} will occur in every \gls{evttrace}. Therefore, they will necessarily always co-occur.
% w.r.t.\ the \todo{Do not forget to talk about language inclusion} one of product-automaton {\autom}, which accepts all and only those sequences of \glspl{evt} that comply with the \glspl{con} already assessed as non-redundant.
% In fact, if the redundancy-check is passed, the \gls{fsa} then $\safecon$ is added to the set of returned \glspl{con}, {\goodconset}, and {\autom} is replaced by its product with the $\safecon$-automaton.

Redundancy and consistency checking of the \glspl{con} $\unsafecon \in \unsafeconlist$ is performed by the ``$\textrm{resolveConflictAndRedundancy}$'' procedure  (\Cref{alg:conflireso}).
The procedure checks the consistency of those \glspl{con} that are not redundant. The redundancy is, again, checked based on the language inclusion of the language generated by the currently analyzed constraint $\languageFunc{A^{\unsafecon}}$ in $\languageFunc{A}$, where $A$ is the automaton that accumulates the contribution of all constraints that have been kept so far. The consistency is checked through a language emptiness test, performed over the intersection of $\languageFunc{A^{\unsafecon}}$ and $\languageFunc{A}$. This is done by checking that $\languageFunc{\autom \times A^{\unsafecon}} \neq \emptyset $.
% Again, product-automaton {\autom} is used to merge the non-conflicting \gls{con}-automata, and therefore it is utilised to verify whether the intersection of languages of {\autom} and the \gls{con}-automaton is empty.
%
In case a conflict is detected, we do not immediately drop the conflicting constraint, but we try, instead, to find a more relaxed constraint that retains its intended semantics as much as possible, but does not incur in a conflict. To do so, we employ the constraint subsumption hierarchy (cf.\ \Cref{sec:minimality}). In particular, we employ the \gls{relaxop} operator \glssymbol{relaxop} to retrieve the parent \gls{con} of the conflicting one, and we recursively invoke the ``$\textrm{resolveConflictAndRedundancy}$'' procedure over the parent. The recursion terminates when the first non-conflicting ancestor of the conflicting constraint is found, or when the top of the hierarchy is reached.
The two cases are resp.\ covered in the example of \Cref{tab:runningexample:output} by {\ChaResp{\taskb}{\taska}}, replaced by {\AltResp{\taskb}{\taska}}, and by {\NotChaSucc{\taska}{\taskd}}, which is removed because a non-conflicting ancestor does not exists.
Note that {\NotChaSucc{\taska}{\taskd}} is to be eliminated because of the interplay of the other two {\NotChaSuccTmp} \glspl{con}, {\Init{\taska}} and {\End{\taskd}}. {\ChaResp{\taskb}{\taska}} is in conflict with {\ChaResp{\taskb}{\taskc}}.

If the \gls{con} under analysis is a \gls{corelacon}, then we know that it is constituted by the conjunction of a corresponding pair of \gls{fw} and \gls{bw} \glspl{con}. In this situation, it could be the case that all the relaxations of the coupling constraint along the subsumption hierarchy continue to be conflicting, but the conflict would be removed by just considering either its forward or backward component (or a relaxation thereof). Consequently, we also recursively invoke the ``$\textrm{resolveConflictAndRedundancy}$'' procedure on these two components.
%(recall that redundancies are considered, hence this would result in a no-op if such components or their relaxation turn out to be implied by the other constraints).

Finally, a last complete pass over \glspl{con} in {\goodconset} is done, to check again whether there are subsumption-hierarchy redundancies. If so, {\goodconset} is pruned accordingly.
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main.tex"
%%% save-place: t
%%% End: 