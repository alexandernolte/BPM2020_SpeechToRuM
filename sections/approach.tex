% !TeX root = ../Main.tex
\section{Interactive Elicitation of Declarative Models}
\label{sec:framework}

\autoref{fig:overview} provides an overview of the main components of the Speech2RuM approach. As shown, the user provides input through speech as well as interaction with the Graphical User Interface (GUI). Based on this input, users are able to construct a declarative process model through three main functions: (1) describing constraints in natural language using speech, (2) augmenting constraints with data- and time-perspectives, and (3) optionally editing and connecting the model's constraints. In the remainder of this section, we will describe each of these three components in detail. 
\todo{do we need to mention how to handle speech or do we put implementation details somewhere else?}

\begin{figure}[!htb]
	\includegraphics[width=\textwidth]{figures/overview}
	\caption{Overview of the Speech2RuM approach}
	\label{fig:overview}
\end{figure}


	

\subsection{Constraint generation}
	\label{sec:texttodeclareconstraints}
	
	In this component, our approach aims to turn a recorded sentence (transformed from speech to text using a standard software library~\cite{whattorefhere?}) into one or more declarative constraints. 
	For this task, we enhanced the existing state-of-the-art approach for the extraction of declarative constraints from natural language text~\cite{vanderaa2019extracting}. 
	
	In particular, we take the result of the parsing step of that existing approach as input to the constraint generation approach. Given a sentence $s$, parsing yields  a list $A_s$ of actions described in the sentence and the inter-relations that exist between the actions, i.e., a mapping $rel_s: A_s \times A_s \rightarrow type$, with $type \in \{xor, and, dep\}$. 	
	  As depicted in \autoref{fig:semanticcomponents}, an action $a \in A_s$ consists of a verb and optional subjects and objects, which may, furthermore, all be augmented with additional information, such as whether or not an action is negated.
	
	\begin{figure}
		\includegraphics[width=0.55\textwidth]{figures/extractedcomponents}
		\caption{Semantic components returned in the parsing step of~\cite{vanderaa2019extracting}}
		\label{fig:semanticcomponents}
	\end{figure}
	
%By building on this parsing step, we extended the existing constraing generation step by: (1) covering considerably more constraints and (2) being able to deal with more flexibility in the input.

	By building on this parsing step and the existing constraint-generation approach, we have added support to handle the additional constraint types presented in \autoref{tab:additionalconstraints}. 	Based on a set of activities $A_s$ and a relation $rel_s$ extracted for a sentence $s$, these additional types are handled as follows:
	\begin{compactitem}
		\item \textbf{\textit{Participation} and \textit{Absence}.} If $A_s$ contains only one action, either an existence or absence constraint is established for the action, depending on whether it is negative or not.
		
		\item \textbf{\textit{AtMostOne}.} If a \PartTmp\ constraint is originally recognized, we subsequently check if $s$ specifies a bound on its number of  executions, i.e., by checking for phrases such as \emph{at most once}, \emph{not more than once}, \emph{one time}. 
		
		\item \textbf{\textit{CoExistence} .} 
		When a sentence has two actions in $A_s$ that are in a relation of type \emph{and} (and without any \emph{dep} relations) are transformed into either a \textit{CoExistence} or a  \textit{NotCoExistence} constraint, depending on whether there is a negation present. 
		
		\item \textbf{\textit{NotCoExistence} .} 
		
		\item \textbf{\textit{RespondedExistence}.} Responded existence constraints are similar to the originally extracted \RespTmp\. Their extraction occurs when two actions are in a dependency relation, i.e., $a_1\ dep\ a_2$ for which it holds that the target action, $a_2$, is indicated to be mandatory, e.g., using \emph{must}. The key difference between \RespTmp\ and \ResExTmp\ is that the former includes a notion of order, i.e., $a_1$ precedes $a_2$, whereas no such order is specified for \ResExTmp\ constraints.
		
	\item \textbf{\textit{ChainPrecedence} and \textit{ChainResponse}.} These constraint types are specializations of \PrecTmp\ \RespTmp\ constraints. Chain constraints are recognized by the presence of a temporal preposition that indicates immediacy. Generally, such a preposition is associated with the verb of either an action $a_1$ or $a_2$ in a relation $a_1\ dep\ a_2$. For this, we consider the preposition  \emph{immediately} and several of its synonyms, i.e., \emph{instantly}, \emph{directly}, and \emph{promptly}. 
	\end{compactitem}
	

	\begin{table}[!ht]
		\caption{Additional constraint types in Speech2RuM}
		\label{tab:additionalconstraints}
		\begin{tabularx}{\textwidth}{lX}
			\textbf{Constraint}  &  \textbf{Example}\\
			\midrule
		\PartTmp & An invoice must be created\\
		\textbf{Absence?} &  Dogs are \uline{not} allowed in the restaurant. \\
			   \UniqTmp & An invoice should be paid \uline{at most once}. \\
			\CoExiTmp &  Order shipment and invoice payment \uline{should occur together}.\\
			\NotCoExiTmp & If an application is accepted, it cannot be rejected. \\
			\ResExTmp &  If a product is produced, it \uline{must be tested}.\\
			\ChaPrecTmp  &  After an order is received, it may  \uline{immediately} be refused.\\
			\ChaRespTmp  &  After an order is received, it must \uline{directly} be  checked.\\
						
			\bottomrule
		\end{tabularx}
	\end{table}
	
	\noindent Note that if a sentence does not yield constraints for these additional types, constraint generation proceeds to extract the six constraint types covered by the original approach. 


	
%	\noindent\textbf{Input flexibility.}
%	
%	- improved pattern recognition. E.g., past tense versus present tense
%
%	- always?	
	
	

\subsection{Multi-Perspective Augmentation}
	\label{sec:multiperspectiveaugmentation}
	
	\textbf{Fabrizio}
	
\subsection{Model Editing and Integration}
	\label{sec:editingandintegration}	

    \textbf{Fabrizio}