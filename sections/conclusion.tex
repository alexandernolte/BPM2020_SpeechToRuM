% !TeX root = ../Main.tex
\section{Conclusion}
\label{sec:conclusion}
%
In this work, we presented an interactive approach that takes vocal statements from the user as input and employs speech recognition to convert them into multi-perspective, declarative process models.
Our Speech2RuM approach goes beyond the state-of-the-art in text-to-constraint transformation by covering a broader range of \Declare\ templates and supporting their augmentation with data and time conditions. The integration of our approach into the RuM toolkit enables users to visualize and edit obtained models in a GUI. Furthermore, it also allows these models to directly serve as a basis for the toolkit's analysis techniques, such as conformance checking and log generation. Finally, we note that the conducted user evaluation represents the first study into the feasibility of using speech recognition for business process modeling. The results demonstrated its promising nature, although they also revealed a clear learning curve.

In future work, we aim to further develop Speech2RuM based on the obtained user feedback. The text-to-constraint component shall be improved to support less natural descriptions, e.g., those that explicitly mention the term \emph{activity} to denote a process step. Furthermore, we want to support the specification of multi-perspective constraints in a single step rather than the current two. Finally, it will be highly interesting to investigate how speech recognition can be lifted to also support the elicitation of imperative process models.